
Facebook eliminó entre abril y septiembre 4,5 millones de contenidos por fomentar el suicidio y las autolesiones. 
Facebook ha eliminado de su red social homónima 4,5 millones de contenidos entre abril y septiembre de este año por vulnerar sus políticas al fomentar el suicidio y las autolesiones, mientras que en Instagram se han eliminado 1,68 millones de publicaciones en el mismo periodo. 
Estos datos aparecen en la cuarta edición del Informe de aplicación de Normas Comunitarias, que comprende el segundo y el tercer trimestre de 2019 y que Facebook ha presentado este miércoles. En él, por primera vez la compañía ha añadido los datos de la red social Instagram, también de su propiedad. 
En este informe, Facebook proporciona datos sobre cuatro áreas de sus políticas: desnudez infantil y explotación sexual infantil; bienes regulados -específicamente, venta ilegal de armas de fuego y drogas-; suicidio y autolesiones; y propaganda terrorista. 
En el primer apartado, de suicidio y autolesiones, Facebook ha tomado medidas sobre aproximadamente 2 millones de piezas de contenido en el segundo trimestre de 2019, de las cuales el 96,1 por ciento fueron detectados de manera proactiva por la compañía. En el tercer trimestre se han eliminado 2,5 millones de piezas de contenido, el 97,1 por ciento detectadas de manera proactiva. 
En Instagram, la compañía ha eliminado aproximadamente 835.000 piezas de contenido en el segundo trimestre de 2019 (77,8 por ciento detectadas), y en el tercer trimestre esta cifra ha alcanzado las 845.000 piezas (aumentando al 79,1 por ciento la detección). 
El contenido que fomenta el suicidio y la autolesión que se ha eliminado de Facebook e Instagram incluye imágenes y representaciones que según la compañía "podrían llevar a otros a comportarse de manera similar". 
El informe recoge también la prevalencia de contenidos sobre suicidio y autolesiones, es decir, la probabilidad de que la gente vea contenidos que violen estas políticas, que en el tercer trimestre ha sido de cuatro entre 10.000. Estos datos incluyen también la venta ilegal de armas de fuego y drogas. 
Asimismo, Facebook ha compartido también sus datos de detección y eliminación de propaganda de grupos terroristas. La tasa de detección proactiva de contenido vinculado a cualquier organización terrorista en Facebook es del 98,5 por ciento y en Instagram del 92,2. En el caso de Al Qaeda, ISIS y sus aliados, su detección en Facebook se ha mantenido por encima del 99 por ciento. 
DESNUDEZ Y EXPLOTACION INFANTIL. 
Otra de las políticas que recoge este informe es la desnudez infantil y explotación sexual de los niños. En Facebook, durante el tercer trimestre de 2019 se han eliminado alrededor de 11,6 millones de piezas de contenido, un aumento con respecto al primer trimestre de 2019, cuando se eliminaron alrededor de 5,8 millones. Durante los últimos cuatro trimestres, la detección proactiva fue de más del 99 por ciento. 
En el caso de Instagram, en el segundo trimestre de 2019 se eliminaron alrededor de 512.000 piezas de contenido, con un 92,5 por ciento de detección proactiva. En el tercer trimestre, los contenido eliminados aumentan a 754.000 piezas de contenido, y mejora la detección (94,6 por ciento). 
El cuarto y último apartado del informe de Facebook son los productos regulados, entre los que se incluye la venta ilegal de armas de fuego y de drogas, prohibida por las políticas de la red social. 
En Facebook, durante el tercer trimestre de 2019 se eliminaron alrededor de 4,4 millones de piezas de contenido de venta de drogas (97,6 por ciento de detección), ascendiendo con respecto a los 841.000 contenidos eliminados del primer trimestre de 2019 (84,4 por ciento de forma proactiva). 
En cuanto a las ventas de armas de fuego, en el tercer trimestre de 2019 se borraron en Facebook alrededor de 2,3 millones de piezas de contenido (93,8 por ciento de detección), un aumento con respecto al primer trimestre, cuando se suprimieron alrededor de 609.000 (69,9 de forma proactiva). 
En Instagram, en el tercer trimestre de 2019 se eliminaron alrededor de 1,5 millones de piezas de contenido de venta de drogas (95,3% de detección) y también alrededor de 58.600 piezas de contenido de ventas de armas de fuego (91,3 de proactividad). 
Facebook ha informado también de la actualización de sus mecanismos automáticos de detección del discurso del odio, con los que la tasa de identificación de contenidos de forma proactiva ha 
aumentado del 68 por ciento del anterior último informe al 80 por ciento del actual. 
